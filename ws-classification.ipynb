{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an image classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tensorflow\n",
    "#%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.9.1\n",
      "Keras version 2.9.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from src.functions import load_fashion_mnist_data\n",
    "from src.lists import class_names\n",
    "\n",
    "print('Tensorflow version', tf.__version__)\n",
    "print('Keras version', keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ... \n",
      "X_train shape (55000, 28, 28)\n",
      "X_train dtype float64\n",
      "X_test shape (10000, 28, 28)\n",
      "X_test dtype uint8\n",
      "X_valid shape (5000, 28, 28)\n",
      "X_valid dtype float64\n",
      "y_train shape (55000,)\n",
      "y_train dtype uint8\n",
      "y_test shape (10000,)\n",
      "y_test dtype uint8\n",
      "y_valid shape (5000,)\n",
      "y_valid dtype uint8\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_valid, y_train, y_test, y_valid = load_fashion_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class names are the following:\n",
      " ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "print(\"The class names are the following:\\n\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Model Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dense(300, activation=\"relu\"),\n",
    "keras.layers.Dense(100, activation=\"relu\"),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the modelâ€™s list of layers\n",
    "print(\"Layers list:\\n\",model.layers)\n",
    "print(\"First layer:\\n\",model.layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For a Dense layer, we have access to  the connection weights and the bias terms:\n",
    "\"\"\"\n",
    "weights, biases = model.layers[3].get_weights()\n",
    "print(\"Weights of layer 4:\\n\", weights)\n",
    "print(\"Shape of weights of layer 4:\\n\",weights.shape)\n",
    "print(\"Biases of layer 4:\\n\",biases)\n",
    "print(\"Shape of biases of layer 4:\\n\",biases.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compile the model to specify the loss function and the optimizer to use.\n",
    "\"\"\"\n",
    "model.compile(\n",
    "loss=\"sparse_categorical_crossentropy\",\n",
    "optimizer=\"sgd\",\n",
    "metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training and Evaluating the Model\n",
    "\"\"\"\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Access models details\n",
    "\"\"\"\n",
    "print(\"Model parameters -->\", history.params)\n",
    "print(\"\")\n",
    "print(\"Model list of epochs it went through -->\", history.epoch)\n",
    "print(\"\")\n",
    "print(\"Models loss and extra metrics it measured at the end of each epoch -->\", history.history)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visualization\")\n",
    "figure(figsize=(20, 15), dpi=150)\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(20, 15))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate the model on test sets\n",
    "\"\"\"\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using the Model to Make Predictions\n",
    "\"\"\"\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "the model estimates one probability per class, from class 0 to class 9. \n",
    "For example, for the first image it estimates that the probability of class 9 (ankle boot) is 100%, \n",
    "for the second image the probability of class 2 (sneaker) is 100%, \n",
    "for the third image the probability of class 1 (sandal) is 100%, and the other classes are negligible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"If you only care about the class with the highest estimated\n",
    "probability (even if that probability is quite low) then you can use the pre\n",
    "dict_classes() method instead:\"\"\"\n",
    "\n",
    "y_pred = (model.predict(X_new) > 0.5).astype(\"int32\")\n",
    "y_pred\n",
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f65f015e90684393145548f440bd1f57356ff2bff1ebecc249e7acd74a09a39e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
